{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cd11c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "# import binarytree as tree\n",
    "from queue import LifoQueue \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "69dd99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the stop word file\n",
    "fObj = open('Stopword-List.txt', 'r')\n",
    "SwContent = fObj.readlines()\n",
    "swlist = [x.replace(\"\\n\",\"\").replace(\" \",\"\") for x in SwContent]\n",
    "swl = [x for x in swlist if x!=\"\"]\n",
    "fObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "98833a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldict = {}\n",
    "ldict1 = {}\n",
    "\n",
    "# Defining the path where the dataset files are stored\n",
    "path = 'Dataset/*'\n",
    "\n",
    "file_list = glob.glob(path)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Looping over all files in the file list\n",
    "for file in file_list:\n",
    "    f = open(file, 'r')\n",
    "    \n",
    "    # Reading the entire file and removing punctuations\n",
    "    full_file = f.read().replace(\".\", \"\").replace(\"n't\", \" not\").replace(\"'\", \"\").replace(\"]\", \" \").replace(\"[\", \"\").replace(\",\", \" \").replace(\"?\", \"\").replace(\"\\n\", \" \").replace(\"-\", \" \").split() \n",
    "\n",
    "    lower_case_doc = [porter.stem(x.lower()) for x in full_file]\n",
    "    \n",
    "    # Removing stop words\n",
    "    without_stop_list = [x for x in lower_case_doc if x not in swl]\n",
    "    \n",
    "    # Trimming the file name and removing redundant '.txt'\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name = file_name.split('.')[0]\n",
    "    \n",
    "    # Storing the file content in the dictionary\n",
    "    ldict[file_name] = lower_case_doc\n",
    "    ldict1[file_name] = without_stop_list\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "# Printing the dictionaries containing file contents\n",
    "# print(\"ldict: \", ldict)\n",
    "# print(\"ldict1: \", ldict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7f1b7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '4', '5', '6', '7', '8', '9'])\n"
     ]
    }
   ],
   "source": [
    "print(ldict.keys())\n",
    "\n",
    "# temp = 'Speeches\\\\speech_0.txt'\n",
    "# p = os.path.basename(temp)\n",
    "# print(p.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f50e0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty dictionary to store the inverted index table\n",
    "index_table = {}\n",
    "\n",
    "# Looping over all keys in the ldict1 dictionary\n",
    "for key in ldict1.keys():\n",
    "    # Looping over all unique words in the key's value\n",
    "    for word in set(ldict1[key]):\n",
    "        if word not in index_table:\n",
    "            index_table[word] = []\n",
    "            index_table[word].append(key)\n",
    "        else:\n",
    "            index_table[word].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3a109bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping over all keys in the index table dictionary\n",
    "for x in index_table.keys():\n",
    "    # Using numpy to find the unique elements and their respective counts in the value list of the current key\n",
    "    unique_elements, counts_elements = np.unique(index_table[x], return_counts=True)\n",
    "    \n",
    "    # Checking if the maximum count of any key in the value list is greater than 1\n",
    "    if counts_elements.max() > 1:\n",
    "        # If the maximum count is greater than 1, printing the current key\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d962be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional index creation\n",
    "\n",
    "pindex_table={}\n",
    "for key in ldict.keys():\n",
    "    count=0\n",
    "    for word in ldict[key]:\n",
    "        count+=1\n",
    "        if word in swl:  # entertaining the presence of stop words in the file (increment index without doing anything)\n",
    "            continue\n",
    "        if word not in pindex_table:\n",
    "            pindex_table[word]={}\n",
    "            pindex_table[word][key]=[]\n",
    "            pindex_table[word][key].append(count)\n",
    "        else:\n",
    "            if key not in pindex_table[word]:\n",
    "                pindex_table[word][key]=[]\n",
    "            pindex_table[word][key].append(count)\n",
    "\n",
    "# print(pindex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "723d31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pindex_table.keys()\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9f25ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proximity query function\n",
    "\n",
    "def ProximityQueryProcessing(w1, w2, ProximityValue, pindex_table):\n",
    "    word1={}\n",
    "    word2={}\n",
    "    for word in pindex_table.keys():\n",
    "        if word == w1:\n",
    "            for docid in pindex_table[word]:\n",
    "                word1[docid]=pindex_table[word][docid]\n",
    "        elif word==w2:\n",
    "            for docid in pindex_table[word]:\n",
    "                word2[docid]=pindex_table[word][docid]\n",
    "                \n",
    "    s1=set(word1.keys())\n",
    "    s2=set(word2.keys())\n",
    "    commonDoc=None\n",
    "    commonDoc=s1.intersection(s2)\n",
    "    \n",
    "    print(\"s1 : \",s1,\"\\n\\ns2 : \",s2)\n",
    "    print(\"\\n\\n## Common in : \",commonDoc,\"\\n\")\n",
    "    listOfTrueDoc=[]\n",
    "    if commonDoc is not None:\n",
    "        for commonDoc in commonDoc:\n",
    "                x=checkPositions(word1[commonDoc],word2[commonDoc], ProximityValue,commonDoc)\n",
    "                if len(x)>0:\n",
    "                    listOfTrueDoc.append(commonDoc)\n",
    "    else:\n",
    "        print(\"result not found\")\n",
    "        \n",
    "    print(\"no of doc in result : \",len(listOfTrueDoc),\"\\nDocs -->\",listOfTrueDoc)\n",
    "    print(\"ProximityQueryProcessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f6306fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def phrasalIntersect(w1,w2,s):\n",
    "#     result=[]\n",
    "#     for pos1 in w1:\n",
    "#         for pos2 in w2:\n",
    "#             if abs(pos1-pos2)==1:\n",
    "#                 result.append(s)\n",
    "#             else:\n",
    "#                 pass\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ebb917bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Boolean_query_processing(stemmedQuery,index_table):\n",
    "#     postfixedquery=listInPostfix(stemmedQuery)\n",
    "    alldoclist=set(ldict.keys())    \n",
    "    \n",
    "#     for multiple NOT Query\n",
    "\n",
    "    if 'and' not in stemmedQuery and 'or' not in stemmedQuery:\n",
    "        countNot=[c for c in stemmedQuery if c=='not']\n",
    "        if len(countNot)%2 == 0:\n",
    "             for word in index_table.keys():\n",
    "                    if word == stemmedQuery[len(countNot)]:\n",
    "                        print(index_table[word])\n",
    "        else:\n",
    "            for word in index_table.keys():\n",
    "                    if word == stemmedQuery[len(countNot)]:\n",
    "                        foundlist=set(index_table[word])\n",
    "                        nfList=alldoclist.difference(foundlist)\n",
    "                        print(\"No of result docs :\",len(nfList),\"\\nDocs -->\",nfList)\n",
    "\n",
    "                        \n",
    "#     for multiple OR Query \n",
    "\n",
    "    elif 'and' not in stemmedQuery and 'not' not in stemmedQuery:\n",
    "        noOR=[c for c in stemmedQuery if c=='or'] \n",
    "        if len(noOR)==1:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "\n",
    "            s=s1.union(s2)\n",
    "            print(\"No of result docs :\",len(s),\"\\nDoc -->\",s)\n",
    "\n",
    "        elif len(noOR)==2:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "            s3=wordFoundList(stemmedQuery[4],index_table)\n",
    "            s=s3.union(s1.union(s2))\n",
    "            print(\"No of result docs :\",len(s),\"\\nDoc -->\",s)\n",
    "\n",
    "        elif len(noOR)==3:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "            s3=wordFoundList(stemmedQuery[4],index_table)\n",
    "            s4=wordFoundList(stemmedQuery[8],index_table)\n",
    "            sf1=s4.union(s3.union(s1.union(s2)))\n",
    "            print(\"No of result docs :\",len(s),\"\\nDocs -->\",s)\n",
    "\n",
    "            \n",
    "#     for multiple AND Query \n",
    "            \n",
    "    elif 'or' not in stemmedQuery and 'not' not in stemmedQuery:\n",
    "        noAnd=[c for c in stemmedQuery if c=='and']\n",
    "\n",
    "        if len(noAnd)==1:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "            s=s1.intersection(s2)\n",
    "            print(\"No of result docs :\",len(s),\"\\nDoc -->\",s)\n",
    "\n",
    "        elif len(noAnd)==2:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "            s3=wordFoundList(stemmedQuery[4],index_table)\n",
    "            s=s3.intersection(s1.intersection(s2))\n",
    "            print(\"No of result docs :\",len(s),\"\\nDocs -->\",s)\n",
    "\n",
    "        elif len(noAnd)==3:\n",
    "            s1=wordFoundList(stemmedQuery[0],index_table)\n",
    "            s2=wordFoundList(stemmedQuery[2],index_table)\n",
    "            s3=wordFoundList(stemmedQuery[4],index_table)\n",
    "            s4=wordFoundList(stemmedQuery[8],index_table)\n",
    "            sf1=s4.intersection(s3.intersection(s1.intersection(s2)))\n",
    "            print(\"No of result docs :\",len(s),\"Docs -->\",s)\n",
    "    else:\n",
    "        print(\"it's a complex query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d5dda76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one word to three word phrasal query processing\n",
    "\n",
    "def phrasalQueryProcessing(Query,pindex_table):\n",
    "    if len(Query)==1:\n",
    "        for word in pindex_table.keys():\n",
    "            if word == Query[0]: \n",
    "                for docid in pindex_table[word]:\n",
    "                    print(docid,\"-->\",pindex_table[word][docid])\n",
    "    elif len(Query)==2 or len(Query)==3:\n",
    "        w1={}\n",
    "        w2={}\n",
    "        w3={}\n",
    "        for word in pindex_table.keys():\n",
    "            if word == Query[0]:\n",
    "                for docid in pindex_table[word]:\n",
    "                    w1[docid]=pindex_table[word][docid]\n",
    "            if word == Query[1]:\n",
    "                for docid in pindex_table[word]:\n",
    "                    w2[docid]=pindex_table[word][docid]\n",
    "            if len(Query)==3:\n",
    "                if word == Query[2]:\n",
    "                    for docid in pindex_table[word]:\n",
    "                        w3[docid]=pindex_table[word][docid]\n",
    "\n",
    "        s1=set(w1.keys())\n",
    "        s2=set(w2.keys())\n",
    "        s=s1.intersection(s2)\n",
    "        myList=[]\n",
    "        if len(Query)==2:\n",
    "            if s is not None:\n",
    "                for s in s:\n",
    "                    x=checkPositions(w1[s], w2[s], 0,s)\n",
    "                    if len(x)>0:\n",
    "                        myList.append(s)\n",
    "        elif len(Query)==3:\n",
    "            myList1=[]\n",
    "            myList2=[]\n",
    "            s3=set(w3.keys())\n",
    "            print(s3)\n",
    "            sl3=s.intersection(s3)\n",
    "            print(\"sl3 --> \",sl3)\n",
    "            if sl3 is not None:\n",
    "                for sl3 in sl3:\n",
    "                    x=checkPositions(w1[sl3], w2[sl3], 0,sl3) \n",
    "                    if len(x)>0:\n",
    "                        myList1.append(sl3)\n",
    "                    y=checkPositions(w2[sl3], w3[sl3], 0,sl3) \n",
    "                    if len(y)>0:\n",
    "                        myList2.append(sl3)\n",
    "                myList=[x for x in myList1 if x in myList2]\n",
    "                    \n",
    "        print(\"no of docs : \",len(myList),\"\\nDocs -->\",myList)\n",
    "        print(\"phrasalQueryProcessing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0abbeeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query good AND chase\n",
      "No of result docs : 5 \n",
      "Doc --> {'28', '30', '2', '27', '16'}\n"
     ]
    }
   ],
   "source": [
    "query=input(\"Enter the query \")\n",
    "\n",
    "# removing punctuations from query\n",
    "query=query.replace(\".\",\"\").replace(\"n't\",\" not\").replace(\"]\",\" \").replace(\"[\",\" \").replace(\",\",\" \").replace(\"?\",\"\").replace(\"/\",\" / \").split()\n",
    "\n",
    "#stemming the query\n",
    "stemmedQuery=[porter.stem(x.lower()) for x in query]\n",
    "\n",
    "# print(stemmedQuery)\n",
    "Boolean_query_processing(stemmedQuery, index_table)\n",
    "\n",
    "QueryWithoutStoplist = [x for x in stemmedQuery if x not in swl]\n",
    "# print(QueryWithoutStoplist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c2085b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of result docs : 10 \n",
      "Doc --> {'3', '18', '2', '27', '22', '19', '9', '25', '16', '23'}\n"
     ]
    }
   ],
   "source": [
    "#query identification part\n",
    "\n",
    "ProximityValue=0\n",
    "\n",
    "#identifying the proximity query\n",
    "if '/' in stemmedQuery:\n",
    "    ProximityValue = int(QueryWithoutStoplist[QueryWithoutStoplist.index('/')+1])\n",
    "    w1=QueryWithoutStoplist[0]\n",
    "    w2=QueryWithoutStoplist[1]\n",
    "    if ProximityValue != 0:\n",
    "        ProximityQueryProcessing(w1,w2,ProximityValue,pindex_table)\n",
    "    else:\n",
    "        print(\"invalid proximity query\")\n",
    "        \n",
    "#identifying the phrasal query        \n",
    "elif 'not' not in stemmedQuery and 'and' not in stemmedQuery and 'or' not in stemmedQuery:\n",
    "    if len(stemmedQuery)!=0:\n",
    "        phrasalQueryProcessing(stemmedQuery,pindex_table)\n",
    "    else:\n",
    "        print(\"the query is null\")\n",
    "    \n",
    "#identifying the boolean query\n",
    "else:\n",
    "    if 'and' in stemmedQuery or 'or' in stemmedQuery or 'not' in stemmedQuery: \n",
    "        Boolean_query_processing(stemmedQuery,index_table)\n",
    "# elif 'not','and','or' in stemmedQuery:\n",
    "#      print(\"its a boolean query\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5b7b0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding list of docs where word has occurred\n",
    "\n",
    "def wordFoundList(w,index_table):\n",
    "#     print(\"in word found func \")\n",
    "\n",
    "    for word in index_table.keys():\n",
    "        if word == w:\n",
    "            return set(index_table[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f7c8cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post fix list to insert into parsing tree for complex queries\n",
    "\n",
    "def listInPostfix(query):\n",
    "    print(\"convert to posfix list\")\n",
    "    prec = {}\n",
    "    prec['not']=3\n",
    "    prec['or']=2\n",
    "    prec['and']=1\n",
    "    pfquery=[]\n",
    "    myStack=LifoQueue()\n",
    "    for q in query:\n",
    "        if q not in 'and' or 'or' or 'not' or '(' or ')':\n",
    "            pfquery.append(q)\n",
    "        elif q=='(':\n",
    "            myStack.push(q)\n",
    "        elif q==')':\n",
    "            topval=myStack.pop()\n",
    "            while topval!='(':\n",
    "                pfquery.append(topval)\n",
    "                topval=myStack.pop()\n",
    "        else:\n",
    "            while (myStack.qsize()!=0) and (prec[myStack.top()]>=prec[q]):\n",
    "                 pfquery.append(myStack.top())\n",
    "            myStack.push(q)\n",
    "                                             \n",
    "    while myStack.qsize() !=0:\n",
    "        pfquery.append(myStack.pop())  \n",
    "                                             \n",
    "    return pfquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4ad02bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check the proximity of two words within a specified distance in a given document\n",
    "def checkPositions(word1, word2, ProximityValue, commonDoc): \n",
    "    result = []\n",
    "    for pos1 in word1:\n",
    "        for pos2 in word2:\n",
    "            # Check if the absolute difference between the positions of word1 and word2 is equal to ProximityValue\n",
    "            if (abs(pos1-pos2)-1) == ProximityValue:\n",
    "                # If the condition is satisfied, print the document ID, positions of word1 and word2, and the proximity value\n",
    "                print(\"DOC--> \",commonDoc,\"-->pos1(\",pos1,\") - pos2(\",pos2,\")\",abs(pos1-pos2)-1)\n",
    "                result.append(commonDoc)\n",
    "            else:\n",
    "                # If the condition is not satisfied, print a false statement with the document ID, positions of word1 and word2, and the proximity value\n",
    "                pass\n",
    "                print(\"false statement : \\n\",\"DOC--> \",commonDoc,\"-->pos1(\",pos1,\") - pos2(\",pos2,\")\",abs(pos1-pos2)-1)\n",
    "    # Return the result list\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa0ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
